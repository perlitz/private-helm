[
    [
        "percent_bfd_neurips_submission_neurips_submission_2",
        {
            "MMLU - EM": 0.6840230960833267,
            "MMLU - EM (Robustness)": 0.6488510804328423,
            "MMLU - EM (Fairness)": 0.6475569359808034,
            "MMLU Mean Win Rate": 0.5925925925925926,
            "TruthfulQA - EM": 0.8852459016393442,
            "TruthfulQA - EM (Robustness)": 0.8032786885245902,
            "TruthfulQA - EM (Fairness)": 0.7377049180327869,
            "TruthfulQA Mean Win Rate": 0.8518518518518519,
            "BIG-bench - EM": 0.38376659451659456,
            "BIG-bench Mean Win Rate": 0.7777777777777778,
            "GSM8K - EM": 0.5081967213114754,
            "GSM8K Mean Win Rate": 0.7777777777777778,
            "BBQ - EM": 0.8852459016393442,
            "BBQ Mean Win Rate": 0.7777777777777778,
            "sam_sum - ROUGE-2": 0.08206169341982592,
            "sam_sum - Stereotypes (race)": null,
            "sam_sum - Stereotypes (gender)": 0.29166666666666663,
            "sam_sum - Representation (race)": 0.4666666666666667,
            "sam_sum - Representation (gender)": 0.0664335664335664,
            "sam_sum Mean Win Rate": 0.4488888888888889,
            "corr2cause - EM": 0.545,
            "corr2cause Mean Win Rate": 0.7777777777777778,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.0933494692853477,
            "MATH Mean Win Rate": 0.4444444444444444,
            "ethics_justice - EM": 0.735,
            "ethics_justice - EM (Robustness)": 0.665,
            "ethics_justice - EM (Fairness)": 0.63,
            "ethics_commonsense - EM": 0.42,
            "ethics_commonsense - EM (Robustness)": 0.275,
            "ethics_commonsense - EM (Fairness)": 0.355,
            "ethics_virtue - EM": 0.915,
            "ethics_virtue - EM (Robustness)": 0.88,
            "ethics_virtue - EM (Fairness)": 0.87,
            "ethics_deontology - EM": 0.585,
            "ethics_deontology - EM (Robustness)": 0.55,
            "ethics_deontology - EM (Fairness)": 0.54,
            "ethics_utilitarianism - EM": 0.535,
            "ethics_utilitarianism - EM (Robustness)": 0.445,
            "ethics_utilitarianism - EM (Fairness)": 0.425,
            "ethics Mean Win Rate": 0.4222222222222222,
            "Score_full": 0.5873287810778356,
            "Score_open": 0.7501314540552354,
            "Score_hidden": 0.5059274445891356
        }
    ],
    [
        "anmolagarwal999_neurips_effeciency_challenge_2023_submission_run_inference_1_lit_gpt",
        {
            "MMLU - EM": 0.6115404253625476,
            "MMLU - EM (Robustness)": 0.5752261540567198,
            "MMLU - EM (Fairness)": 0.5813313096510396,
            "MMLU Mean Win Rate": 0.1111111111111111,
            "TruthfulQA - EM": 0.8688524590163934,
            "TruthfulQA - EM (Robustness)": 0.7868852459016393,
            "TruthfulQA - EM (Fairness)": 0.819672131147541,
            "TruthfulQA Mean Win Rate": 0.8148148148148148,
            "BIG-bench - EM": 0.39621349730019084,
            "BIG-bench Mean Win Rate": 0.8888888888888888,
            "GSM8K - EM": 0.26229508196721313,
            "GSM8K Mean Win Rate": 0.5555555555555556,
            "BBQ - EM": 1.0,
            "BBQ Mean Win Rate": 0.8888888888888888,
            "sam_sum - ROUGE-2": 0.005689827665728247,
            "sam_sum - Stereotypes (race)": null,
            "sam_sum - Stereotypes (gender)": 0.5,
            "sam_sum - Representation (race)": 0.6666666666666667,
            "sam_sum - Representation (gender)": 0.08333333333333334,
            "sam_sum Mean Win Rate": 0.20444444444444443,
            "corr2cause - EM": 0.54,
            "corr2cause Mean Win Rate": 0.6666666666666666,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.13732057210559803,
            "MATH Mean Win Rate": 0.7777777777777778,
            "ethics_justice - EM": 0.685,
            "ethics_justice - EM (Robustness)": 0.64,
            "ethics_justice - EM (Fairness)": 0.63,
            "ethics_commonsense - EM": 0.415,
            "ethics_commonsense - EM (Robustness)": 0.315,
            "ethics_commonsense - EM (Fairness)": 0.395,
            "ethics_virtue - EM": 0.86,
            "ethics_virtue - EM (Robustness)": 0.82,
            "ethics_virtue - EM (Fairness)": 0.845,
            "ethics_deontology - EM": 0.57,
            "ethics_deontology - EM (Robustness)": 0.515,
            "ethics_deontology - EM (Fairness)": 0.54,
            "ethics_utilitarianism - EM": 0.58,
            "ethics_utilitarianism - EM (Robustness)": 0.485,
            "ethics_utilitarianism - EM (Fairness)": 0.545,
            "ethics Mean Win Rate": 0.35802469135802467,
            "Score_full": 0.46912817826466235,
            "Score_open": 0.5246235373942086,
            "Score_hidden": 0.4413804986998893
        }
    ],
    [
        "mrigankraman_llm_comp_a100_submissions_a100_1st_submission",
        {
            "MMLU - EM": 0.6741430522685955,
            "MMLU - EM (Robustness)": 0.6527266409645438,
            "MMLU - EM (Fairness)": 0.6588733310439052,
            "MMLU Mean Win Rate": 0.7037037037037037,
            "TruthfulQA - EM": 0.8032786885245902,
            "TruthfulQA - EM (Robustness)": 0.7704918032786885,
            "TruthfulQA - EM (Fairness)": 0.4207650273224044,
            "TruthfulQA Mean Win Rate": 0.48148148148148145,
            "BIG-bench - EM": 0.33080993778118384,
            "BIG-bench Mean Win Rate": 0.6666666666666666,
            "GSM8K - EM": 0.27049180327868855,
            "GSM8K Mean Win Rate": 0.6666666666666666,
            "BBQ - EM": 0.7595628415300546,
            "BBQ Mean Win Rate": 0.4444444444444444,
            "sam_sum - ROUGE-2": 0.01211502329176853,
            "sam_sum - Stereotypes (race)": null,
            "sam_sum - Stereotypes (gender)": 0.4375,
            "sam_sum - Representation (race)": 0.3333333333333333,
            "sam_sum - Representation (gender)": 0.25274725274725274,
            "sam_sum Mean Win Rate": 0.33777777777777773,
            "corr2cause - EM": 0.52875,
            "corr2cause Mean Win Rate": 0.5555555555555556,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.07037170164486695,
            "MATH Mean Win Rate": 0.2222222222222222,
            "ethics_justice - EM": 0.8275,
            "ethics_justice - EM (Robustness)": 0.69,
            "ethics_justice - EM (Fairness)": 0.6675,
            "ethics_commonsense - EM": 0.4025,
            "ethics_commonsense - EM (Robustness)": 0.355,
            "ethics_commonsense - EM (Fairness)": 0.385,
            "ethics_virtue - EM": 0.6225,
            "ethics_virtue - EM (Robustness)": 0.465,
            "ethics_virtue - EM (Fairness)": 0.575,
            "ethics_deontology - EM": 0.6675,
            "ethics_deontology - EM (Robustness)": 0.515,
            "ethics_deontology - EM (Fairness)": 0.635,
            "ethics_utilitarianism - EM": 0.77,
            "ethics_utilitarianism - EM (Robustness)": 0.4075,
            "ethics_utilitarianism - EM (Fairness)": 0.7325,
            "ethics Mean Win Rate": 0.47407407407407404,
            "Score_full": 0.44406930710308323,
            "Score_open": 0.5822652578602974,
            "Score_hidden": 0.37497133172447616
        }
    ],
    [
        "lingjoor_research_llm_efficiency_submission",
        {
            "MMLU - EM": 0.6866839846209393,
            "MMLU - EM (Robustness)": 0.6488656094819899,
            "MMLU - EM (Fairness)": 0.6518032274196081,
            "MMLU Mean Win Rate": 0.7407407407407407,
            "TruthfulQA - EM": 0.5737704918032787,
            "TruthfulQA - EM (Robustness)": 0.4918032786885246,
            "TruthfulQA - EM (Fairness)": 0.4426229508196721,
            "TruthfulQA Mean Win Rate": 0.24074074074074073,
            "BIG-bench - EM": 0.00125,
            "BIG-bench Mean Win Rate": 0.2222222222222222,
            "GSM8K - EM": 0.13114754098360656,
            "GSM8K Mean Win Rate": 0.3333333333333333,
            "BBQ - EM": 0.7540983606557377,
            "BBQ Mean Win Rate": 0.3333333333333333,
            "sam_sum - ROUGE-2": 0.1522558402954788,
            "sam_sum - Stereotypes (race)": 0.6666666666666667,
            "sam_sum - Stereotypes (gender)": 0.3009451379127605,
            "sam_sum - Representation (race)": 0.33333333333333337,
            "sam_sum - Representation (gender)": 0.006677796327212021,
            "sam_sum Mean Win Rate": 0.7611111111111111,
            "corr2cause - EM": 0.4925,
            "corr2cause Mean Win Rate": 0.1111111111111111,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.133808213654396,
            "MATH Mean Win Rate": 0.6666666666666666,
            "ethics_justice - EM": 0.685,
            "ethics_justice - EM (Robustness)": 0.635,
            "ethics_justice - EM (Fairness)": 0.56,
            "ethics_commonsense - EM": 0.445,
            "ethics_commonsense - EM (Robustness)": 0.32,
            "ethics_commonsense - EM (Fairness)": 0.4,
            "ethics_virtue - EM": 0.79,
            "ethics_virtue - EM (Robustness)": 0.705,
            "ethics_virtue - EM (Fairness)": 0.72,
            "ethics_deontology - EM": 0.75,
            "ethics_deontology - EM (Robustness)": 0.61,
            "ethics_deontology - EM (Fairness)": 0.55,
            "ethics_utilitarianism - EM": 0.625,
            "ethics_utilitarianism - EM (Robustness)": 0.47,
            "ethics_utilitarianism - EM (Fairness)": 0.48,
            "ethics Mean Win Rate": 0.4024691358024691,
            "Score_full": 0.37136809140082283,
            "Score_open": 0.3378719669950218,
            "Score_hidden": 0.3881161536037234
        }
    ],
    [
        "kowndinya_renduchintala_efficientguys23_reproduce_eval",
        {
            "MMLU - EM": 0.6437186671101672,
            "MMLU - EM (Robustness)": 0.5896484470590861,
            "MMLU - EM (Fairness)": 0.603834359498587,
            "MMLU Mean Win Rate": 0.2222222222222222,
            "TruthfulQA - EM": 0.6229508196721312,
            "TruthfulQA - EM (Robustness)": 0.5409836065573771,
            "TruthfulQA - EM (Fairness)": 0.47540983606557374,
            "TruthfulQA Mean Win Rate": 0.41975308641975306,
            "BIG-bench - EM": 0.03432258064516129,
            "BIG-bench Mean Win Rate": 0.3333333333333333,
            "GSM8K - EM": 0.0,
            "GSM8K Mean Win Rate": 0.037037037037037035,
            "BBQ - EM": 0.7704918032786885,
            "BBQ Mean Win Rate": 0.5555555555555556,
            "sam_sum - ROUGE-2": 0.11608681289077498,
            "sam_sum - Stereotypes (race)": 0.6666666666666667,
            "sam_sum - Stereotypes (gender)": 0.37690641167430333,
            "sam_sum - Representation (race)": 0.3589743589743589,
            "sam_sum - Representation (gender)": 0.07078189300411522,
            "sam_sum Mean Win Rate": 0.5833333333333334,
            "corr2cause - EM": 0.6525,
            "corr2cause Mean Win Rate": 0.8888888888888888,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.03382100972908979,
            "MATH Mean Win Rate": 0.1111111111111111,
            "ethics_justice - EM": 0.725,
            "ethics_justice - EM (Robustness)": 0.62,
            "ethics_justice - EM (Fairness)": 0.625,
            "ethics_commonsense - EM": 0.485,
            "ethics_commonsense - EM (Robustness)": 0.355,
            "ethics_commonsense - EM (Fairness)": 0.395,
            "ethics_virtue - EM": 0.89,
            "ethics_virtue - EM (Robustness)": 0.865,
            "ethics_virtue - EM (Fairness)": 0.865,
            "ethics_deontology - EM": 0.52,
            "ethics_deontology - EM (Robustness)": 0.49,
            "ethics_deontology - EM (Fairness)": 0.505,
            "ethics_utilitarianism - EM": 0.76,
            "ethics_utilitarianism - EM (Robustness)": 0.65,
            "ethics_utilitarianism - EM (Fairness)": 0.695,
            "ethics Mean Win Rate": 0.537037037037037,
            "Score_full": 0.3561763639747172,
            "Score_open": 0.22972315492828954,
            "Score_hidden": 0.41940296849793113
        }
    ],
    [
        "hqbbzsp_nips_submission_a100_submission_of_a100_submission_1",
        {
            "MMLU - EM": 0.684928073849408,
            "MMLU - EM (Robustness)": 0.6383858048634294,
            "MMLU - EM (Fairness)": 0.6631659144401898,
            "MMLU Mean Win Rate": 0.7037037037037037,
            "TruthfulQA - EM": 0.6229508196721312,
            "TruthfulQA - EM (Robustness)": 0.5245901639344263,
            "TruthfulQA - EM (Fairness)": 0.5245901639344263,
            "TruthfulQA Mean Win Rate": 0.4382716049382716,
            "BIG-bench - EM": 0.0,
            "BIG-bench Mean Win Rate": 0.05555555555555555,
            "GSM8K - EM": null,
            "GSM8K Mean Win Rate": 0.037037037037037035,
            "BBQ - EM": null,
            "BBQ Mean Win Rate": 0.0,
            "sam_sum - ROUGE-2": 0.17415386430598975,
            "sam_sum - Stereotypes (race)": 0.6666666666666667,
            "sam_sum - Stereotypes (gender)": 0.3887327710603573,
            "sam_sum - Representation (race)": 0.3666666666666667,
            "sam_sum - Representation (gender)": 0.034075104311543786,
            "sam_sum Mean Win Rate": 0.6277777777777778,
            "corr2cause - EM": 0.505,
            "corr2cause Mean Win Rate": 0.3888888888888889,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.10161606164200679,
            "MATH Mean Win Rate": 0.5555555555555556,
            "ethics_justice - EM": 0.72,
            "ethics_justice - EM (Robustness)": 0.65,
            "ethics_justice - EM (Fairness)": 0.64,
            "ethics_commonsense - EM": 0.405,
            "ethics_commonsense - EM (Robustness)": 0.325,
            "ethics_commonsense - EM (Fairness)": 0.35,
            "ethics_virtue - EM": 0.78,
            "ethics_virtue - EM (Robustness)": 0.66,
            "ethics_virtue - EM (Fairness)": 0.71,
            "ethics_deontology - EM": 0.765,
            "ethics_deontology - EM (Robustness)": 0.655,
            "ethics_deontology - EM (Fairness)": 0.625,
            "ethics_utilitarianism - EM": 0.675,
            "ethics_utilitarianism - EM (Robustness)": 0.615,
            "ethics_utilitarianism - EM (Fairness)": 0.545,
            "ethics Mean Win Rate": 0.5,
            "Score_full": 0.3402052286733238,
            "Score_open": 5.00329732230967e-66,
            "Score_hidden": 0.5103078430099858
        }
    ],
    [
        "datta0_neurips_submission",
        {
            "MMLU - EM": 0.6819618547946719,
            "MMLU - EM (Robustness)": 0.6447183266744201,
            "MMLU - EM (Fairness)": 0.6529470078815702,
            "MMLU Mean Win Rate": 0.5925925925925926,
            "TruthfulQA - EM": 0.5573770491803278,
            "TruthfulQA - EM (Robustness)": 0.45901639344262296,
            "TruthfulQA - EM (Fairness)": 0.4426229508196721,
            "TruthfulQA Mean Win Rate": 0.16666666666666666,
            "BIG-bench - EM": 0.03433116883116883,
            "BIG-bench Mean Win Rate": 0.4444444444444444,
            "GSM8K - EM": 0.14754098360655737,
            "GSM8K Mean Win Rate": 0.4444444444444444,
            "BBQ - EM": 0.7377049180327869,
            "BBQ Mean Win Rate": 0.2222222222222222,
            "sam_sum - ROUGE-2": null,
            "sam_sum - Stereotypes (race)": null,
            "sam_sum - Stereotypes (gender)": null,
            "sam_sum - Representation (race)": null,
            "sam_sum - Representation (gender)": null,
            "sam_sum Mean Win Rate": 0.026666666666666665,
            "corr2cause - EM": 0.505,
            "corr2cause Mean Win Rate": 0.3888888888888889,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.07321227183161949,
            "MATH Mean Win Rate": 0.3333333333333333,
            "ethics_justice - EM": 0.69,
            "ethics_justice - EM (Robustness)": 0.62,
            "ethics_justice - EM (Fairness)": 0.58,
            "ethics_commonsense - EM": 0.445,
            "ethics_commonsense - EM (Robustness)": 0.345,
            "ethics_commonsense - EM (Fairness)": 0.42,
            "ethics_virtue - EM": 0.855,
            "ethics_virtue - EM (Robustness)": 0.775,
            "ethics_virtue - EM (Fairness)": 0.785,
            "ethics_deontology - EM": 0.72,
            "ethics_deontology - EM (Robustness)": 0.595,
            "ethics_deontology - EM (Fairness)": 0.555,
            "ethics_utilitarianism - EM": 0.61,
            "ethics_utilitarianism - EM (Robustness)": 0.5,
            "ethics_utilitarianism - EM (Fairness)": 0.5,
            "ethics Mean Win Rate": 0.4703703703703704,
            "Score_full": 0.24614644786727666,
            "Score_open": 0.33682590366897736,
            "Score_hidden": 0.20080671996642632
        }
    ],
    [
        "quyanh2005_neurips_llm_challenge_a100_qwen_14b_neurips_v1",
        {
            "MMLU - EM": 0.5718654209879938,
            "MMLU - EM (Robustness)": 0.5319934944343896,
            "MMLU - EM (Fairness)": 0.5426821473394794,
            "MMLU Mean Win Rate": 0.0,
            "TruthfulQA - EM": 0.4426229508196721,
            "TruthfulQA - EM (Robustness)": 0.39344262295081966,
            "TruthfulQA - EM (Fairness)": 0.39344262295081966,
            "TruthfulQA Mean Win Rate": 0.0,
            "BIG-bench - EM": 0.245707221019721,
            "BIG-bench Mean Win Rate": 0.5555555555555556,
            "GSM8K - EM": 0.5573770491803278,
            "GSM8K Mean Win Rate": 0.8888888888888888,
            "BBQ - EM": 0.5245901639344263,
            "BBQ Mean Win Rate": 0.1111111111111111,
            "sam_sum - ROUGE-2": 0.00043122662170281227,
            "sam_sum - Stereotypes (race)": null,
            "sam_sum - Stereotypes (gender)": null,
            "sam_sum - Representation (race)": null,
            "sam_sum - Representation (gender)": 0.24999999999999994,
            "sam_sum Mean Win Rate": 0.09333333333333332,
            "corr2cause - EM": 0.5025,
            "corr2cause Mean Win Rate": 0.2222222222222222,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.1756685072196562,
            "MATH Mean Win Rate": 0.8888888888888888,
            "ethics_justice - EM": 0.685,
            "ethics_justice - EM (Robustness)": 0.615,
            "ethics_justice - EM (Fairness)": 0.535,
            "ethics_commonsense - EM": 0.51,
            "ethics_commonsense - EM (Robustness)": 0.345,
            "ethics_commonsense - EM (Fairness)": 0.465,
            "ethics_virtue - EM": 0.895,
            "ethics_virtue - EM (Robustness)": 0.795,
            "ethics_virtue - EM (Fairness)": 0.845,
            "ethics_deontology - EM": 0.68,
            "ethics_deontology - EM (Robustness)": 0.575,
            "ethics_deontology - EM (Fairness)": 0.525,
            "ethics_utilitarianism - EM": 0.595,
            "ethics_utilitarianism - EM (Robustness)": 0.51,
            "ethics_utilitarianism - EM (Fairness)": 0.55,
            "ethics Mean Win Rate": 0.4617283950617284,
            "Score_full": 0.20249920469009713,
            "Score_open": 2.6630563450495956e-130,
            "Score_hidden": 0.30374880703514573
        }
    ],
    [
        "vinairesearch_vinai_neurips_llm_efficiency_submit_c",
        {
            "MMLU - EM": 0.6490862540686632,
            "MMLU - EM (Robustness)": 0.6051619394146837,
            "MMLU - EM (Fairness)": 0.607589547457265,
            "MMLU Mean Win Rate": 0.3333333333333333,
            "TruthfulQA - EM": 0.6229508196721312,
            "TruthfulQA - EM (Robustness)": 0.5737704918032787,
            "TruthfulQA - EM (Fairness)": 0.5245901639344263,
            "TruthfulQA Mean Win Rate": 0.5123456790123457,
            "BIG-bench - EM": 0.0,
            "BIG-bench Mean Win Rate": 0.05555555555555555,
            "GSM8K - EM": 0.0,
            "GSM8K Mean Win Rate": 0.037037037037037035,
            "BBQ - EM": 0.8688524590163934,
            "BBQ Mean Win Rate": 0.6666666666666666,
            "sam_sum - ROUGE-2": 0.08701215897026197,
            "sam_sum - Stereotypes (race)": 0.6666666666666667,
            "sam_sum - Stereotypes (gender)": 0.3663754989918673,
            "sam_sum - Representation (race)": 0.38095238095238093,
            "sam_sum - Representation (gender)": 0.011651469098277606,
            "sam_sum Mean Win Rate": 0.6055555555555555,
            "corr2cause - EM": 0.4725,
            "corr2cause Mean Win Rate": 0.0,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.020273394754491865,
            "MATH Mean Win Rate": 0.0,
            "ethics_justice - EM": 0.705,
            "ethics_justice - EM (Robustness)": 0.635,
            "ethics_justice - EM (Fairness)": 0.61,
            "ethics_commonsense - EM": 0.43,
            "ethics_commonsense - EM (Robustness)": 0.28,
            "ethics_commonsense - EM (Fairness)": 0.375,
            "ethics_virtue - EM": 0.75,
            "ethics_virtue - EM (Robustness)": 0.575,
            "ethics_virtue - EM (Fairness)": 0.66,
            "ethics_deontology - EM": 0.59,
            "ethics_deontology - EM (Robustness)": 0.535,
            "ethics_deontology - EM (Fairness)": 0.545,
            "ethics_utilitarianism - EM": 0.725,
            "ethics_utilitarianism - EM (Robustness)": 0.575,
            "ethics_utilitarianism - EM (Fairness)": 0.655,
            "ethics Mean Win Rate": 0.3592592592592592,
            "Score_full": 0.06263565224641449,
            "Score_open": 0.18790695673924349,
            "Score_hidden": 1.518038615500152e-162
        }
    ]
]