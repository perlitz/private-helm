[
    [
        "akjindal53244_neurips_submission_submission_2",
        {
            "MMLU - EM": 0.629344478816052,
            "MMLU - EM (Robustness)": 0.5913632362415081,
            "MMLU - EM (Fairness)": 0.5962301959853324,
            "MMLU Mean Win Rate": 0.4166666666666667,
            "TruthfulQA - EM": 0.5901639344262295,
            "TruthfulQA - EM (Robustness)": 0.5409836065573771,
            "TruthfulQA - EM (Fairness)": 0.4918032786885246,
            "TruthfulQA Mean Win Rate": 0.75,
            "BIG-bench - EM": 0.33034628543499506,
            "BIG-bench Mean Win Rate": 0.75,
            "GSM8K - EM": 0.4426229508196721,
            "GSM8K Mean Win Rate": 0.625,
            "BBQ - EM": 0.7377049180327869,
            "BBQ Mean Win Rate": 0.25,
            "sam_sum - ROUGE-2": 0.12706189029528125,
            "sam_sum - Stereotypes (race)": 0.6666666666666667,
            "sam_sum - Stereotypes (gender)": 0.447156862745098,
            "sam_sum - Representation (race)": 0.45833333333333326,
            "sam_sum - Representation (gender)": 0.012639029322548012,
            "sam_sum Mean Win Rate": 0.38333333333333336,
            "corr2cause - EM": 0.615,
            "corr2cause Mean Win Rate": 0.875,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.12094975385375681,
            "MATH Mean Win Rate": 0.75,
            "ethics_justice - EM": 0.68,
            "ethics_justice - EM (Robustness)": 0.645,
            "ethics_justice - EM (Fairness)": 0.62,
            "ethics_commonsense - EM": 0.41,
            "ethics_commonsense - EM (Robustness)": 0.33,
            "ethics_commonsense - EM (Fairness)": 0.345,
            "ethics_virtue - EM": 0.895,
            "ethics_virtue - EM (Robustness)": 0.865,
            "ethics_virtue - EM (Fairness)": 0.86,
            "ethics_deontology - EM": 0.63,
            "ethics_deontology - EM (Robustness)": 0.585,
            "ethics_deontology - EM (Fairness)": 0.595,
            "ethics_utilitarianism - EM": 0.72,
            "ethics_utilitarianism - EM (Robustness)": 0.6,
            "ethics_utilitarianism - EM (Fairness)": 0.645,
            "ethics Mean Win Rate": 0.55,
            "Score_full": 0.5786321747001768,
            "Score_open": 0.516114739666671,
            "Score_hidden": 0.6098908922169298
        }
    ],
    [
        "mrigankraman_llm_comp_4090_submissions_4090_1st_submission",
        {
            "MMLU - EM": 0.6870242923571095,
            "MMLU - EM (Robustness)": 0.6448122712575286,
            "MMLU - EM (Fairness)": 0.6469063080335244,
            "MMLU Mean Win Rate": 0.875,
            "TruthfulQA - EM": 0.5245901639344263,
            "TruthfulQA - EM (Robustness)": 0.5245901639344263,
            "TruthfulQA - EM (Fairness)": 0.4426229508196721,
            "TruthfulQA Mean Win Rate": 0.2847222222222222,
            "BIG-bench - EM": 0.37611151453086933,
            "BIG-bench Mean Win Rate": 0.875,
            "GSM8K - EM": 0.5737704918032787,
            "GSM8K Mean Win Rate": 0.8125,
            "BBQ - EM": 0.8524590163934426,
            "BBQ Mean Win Rate": 0.5625,
            "sam_sum - ROUGE-2": 0.03440952597928738,
            "sam_sum - Stereotypes (race)": null,
            "sam_sum - Stereotypes (gender)": 0.4166666666666667,
            "sam_sum - Representation (race)": 0.6231884057971013,
            "sam_sum - Representation (gender)": 0.0017921146953405187,
            "sam_sum Mean Win Rate": 0.20833333333333334,
            "corr2cause - EM": 0.4725,
            "corr2cause Mean Win Rate": 0.25,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.06771820758106896,
            "MATH Mean Win Rate": 0.5,
            "ethics_justice - EM": 0.685,
            "ethics_justice - EM (Robustness)": 0.665,
            "ethics_justice - EM (Fairness)": 0.58,
            "ethics_commonsense - EM": 0.525,
            "ethics_commonsense - EM (Robustness)": 0.45,
            "ethics_commonsense - EM (Fairness)": 0.5,
            "ethics_virtue - EM": 0.77,
            "ethics_virtue - EM (Robustness)": 0.705,
            "ethics_virtue - EM (Fairness)": 0.69,
            "ethics_deontology - EM": 0.585,
            "ethics_deontology - EM (Robustness)": 0.49,
            "ethics_deontology - EM (Fairness)": 0.53,
            "ethics_utilitarianism - EM": 0.55,
            "ethics_utilitarianism - EM (Robustness)": 0.345,
            "ethics_utilitarianism - EM (Fairness)": 0.405,
            "ethics Mean Win Rate": 0.4083333333333333,
            "Score_full": 0.4242443418435959,
            "Score_open": 0.6304877797779268,
            "Score_hidden": 0.32112262287643045
        }
    ],
    [
        "quyanh2005_neurips_llm_challenge_4090_mistral_7b_neurips_v2",
        {
            "MMLU - EM": 0.6393927994793461,
            "MMLU - EM (Robustness)": 0.5961320636707633,
            "MMLU - EM (Fairness)": 0.5939914031773024,
            "MMLU Mean Win Rate": 0.4583333333333333,
            "TruthfulQA - EM": 0.5737704918032787,
            "TruthfulQA - EM (Robustness)": 0.5245901639344263,
            "TruthfulQA - EM (Fairness)": 0.45901639344262296,
            "TruthfulQA Mean Win Rate": 0.5625,
            "BIG-bench - EM": 0.0,
            "BIG-bench Mean Win Rate": 0.0625,
            "GSM8K - EM": 0.0,
            "GSM8K Mean Win Rate": 0.03125,
            "BBQ - EM": 0.9344262295081968,
            "BBQ Mean Win Rate": 0.75,
            "sam_sum - ROUGE-2": 0.09847386579369953,
            "sam_sum - Stereotypes (race)": 0.6666666666666666,
            "sam_sum - Stereotypes (gender)": 0.3392468339351674,
            "sam_sum - Representation (race)": 0.37931034482758624,
            "sam_sum - Representation (gender)": 0.005609284332688591,
            "sam_sum Mean Win Rate": 0.65,
            "corr2cause - EM": 0.4975,
            "corr2cause Mean Win Rate": 0.625,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.035745206732975446,
            "MATH Mean Win Rate": 0.25,
            "ethics_justice - EM": 0.7,
            "ethics_justice - EM (Robustness)": 0.65,
            "ethics_justice - EM (Fairness)": 0.64,
            "ethics_commonsense - EM": 0.49,
            "ethics_commonsense - EM (Robustness)": 0.43,
            "ethics_commonsense - EM (Fairness)": 0.45,
            "ethics_virtue - EM": 0.74,
            "ethics_virtue - EM (Robustness)": 0.67,
            "ethics_virtue - EM (Fairness)": 0.695,
            "ethics_deontology - EM": 0.6,
            "ethics_deontology - EM (Robustness)": 0.52,
            "ethics_deontology - EM (Fairness)": 0.495,
            "ethics_utilitarianism - EM": 0.565,
            "ethics_utilitarianism - EM (Robustness)": 0.45,
            "ethics_utilitarianism - EM (Fairness)": 0.52,
            "ethics Mean Win Rate": 0.475,
            "Score_full": 0.38135164714118186,
            "Score_open": 0.20673740209107416,
            "Score_hidden": 0.4686587696662357
        }
    ],
    [
        "agoncharenko1992_llm_eff_challenge_mistral_mistral_eval",
        {
            "MMLU - EM": 0.5720515513946133,
            "MMLU - EM (Robustness)": 0.550252476069518,
            "MMLU - EM (Fairness)": 0.5538559159732673,
            "MMLU Mean Win Rate": 0.0,
            "TruthfulQA - EM": 0.819672131147541,
            "TruthfulQA - EM (Robustness)": 0.7622950819672132,
            "TruthfulQA - EM (Fairness)": 0.6366120218579234,
            "TruthfulQA Mean Win Rate": 0.875,
            "BIG-bench - EM": 0.0,
            "BIG-bench Mean Win Rate": 0.0625,
            "GSM8K - EM": 0.0,
            "GSM8K Mean Win Rate": 0.03125,
            "BBQ - EM": 0.9426229508196722,
            "BBQ Mean Win Rate": 0.875,
            "sam_sum - ROUGE-2": 0.1018290811173641,
            "sam_sum - Stereotypes (race)": 0.3333333333333333,
            "sam_sum - Stereotypes (gender)": 0.29377679164464665,
            "sam_sum - Representation (race)": 0.5,
            "sam_sum - Representation (gender)": 0.07522904260192395,
            "sam_sum Mean Win Rate": 0.5,
            "corr2cause - EM": 0.53375,
            "corr2cause Mean Win Rate": 0.75,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.07393436756390795,
            "MATH Mean Win Rate": 0.625,
            "ethics_justice - EM": 0.48,
            "ethics_justice - EM (Robustness)": 0.465,
            "ethics_justice - EM (Fairness)": 0.4325,
            "ethics_commonsense - EM": 0.495,
            "ethics_commonsense - EM (Robustness)": 0.48,
            "ethics_commonsense - EM (Fairness)": 0.49,
            "ethics_virtue - EM": 0.78,
            "ethics_virtue - EM (Robustness)": 0.485,
            "ethics_virtue - EM (Fairness)": 0.745,
            "ethics_deontology - EM": 0.4525,
            "ethics_deontology - EM (Robustness)": 0.4,
            "ethics_deontology - EM (Fairness)": 0.4125,
            "ethics_utilitarianism - EM": 0.7424999999999999,
            "ethics_utilitarianism - EM (Robustness)": 0.7,
            "ethics_utilitarianism - EM (Fairness)": 0.7075,
            "ethics Mean Win Rate": 0.4083333333333333,
            "Score_full": 0.37080046552117163,
            "Score_open": 5.93890202060757e-66,
            "Score_hidden": 0.5562006982817574
        }
    ],
    [
        "tvergho_lm_neurips_train",
        {
            "MMLU - EM": 0.6250014526393641,
            "MMLU - EM (Robustness)": 0.5869270130063827,
            "MMLU - EM (Fairness)": 0.5917902903457365,
            "MMLU Mean Win Rate": 0.16666666666666666,
            "TruthfulQA - EM": 0.5737704918032787,
            "TruthfulQA - EM (Robustness)": 0.4918032786885246,
            "TruthfulQA - EM (Fairness)": 0.45901639344262296,
            "TruthfulQA Mean Win Rate": 0.5,
            "BIG-bench - EM": 0.25005540524290537,
            "BIG-bench Mean Win Rate": 0.625,
            "GSM8K - EM": 0.2459016393442623,
            "GSM8K Mean Win Rate": 0.5,
            "BBQ - EM": 0.7213114754098361,
            "BBQ Mean Win Rate": 0.125,
            "sam_sum - ROUGE-2": 0.09539741944673753,
            "sam_sum - Stereotypes (race)": null,
            "sam_sum - Stereotypes (gender)": 0.3869556913674561,
            "sam_sum - Representation (race)": 0.3939393939393939,
            "sam_sum - Representation (gender)": 0.006254598969830771,
            "sam_sum Mean Win Rate": 0.35833333333333334,
            "corr2cause - EM": 0.4775,
            "corr2cause Mean Win Rate": 0.375,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.06009999493135149,
            "MATH Mean Win Rate": 0.375,
            "ethics_justice - EM": 0.685,
            "ethics_justice - EM (Robustness)": 0.645,
            "ethics_justice - EM (Fairness)": 0.64,
            "ethics_commonsense - EM": 0.44,
            "ethics_commonsense - EM (Robustness)": 0.3,
            "ethics_commonsense - EM (Fairness)": 0.375,
            "ethics_virtue - EM": 0.84,
            "ethics_virtue - EM (Robustness)": 0.76,
            "ethics_virtue - EM (Fairness)": 0.805,
            "ethics_deontology - EM": 0.59,
            "ethics_deontology - EM (Robustness)": 0.515,
            "ethics_deontology - EM (Fairness)": 0.54,
            "ethics_utilitarianism - EM": 0.565,
            "ethics_utilitarianism - EM (Robustness)": 0.515,
            "ethics_utilitarianism - EM (Fairness)": 0.53,
            "ethics Mean Win Rate": 0.43333333333333335,
            "Score_full": 0.36229395700548067,
            "Score_open": 0.31806490913484803,
            "Score_hidden": 0.38440848094079705
        }
    ],
    [
        "hfvienna_unimportant_submission_4090_3_fine_tune_2_submission_4090_3_fine_tune_2",
        {
            "MMLU - EM": 0.6446918698776283,
            "MMLU - EM (Robustness)": 0.5991941716850246,
            "MMLU - EM (Fairness)": 0.595201900548087,
            "MMLU Mean Win Rate": 0.5833333333333334,
            "TruthfulQA - EM": 0.5409836065573771,
            "TruthfulQA - EM (Robustness)": 0.4426229508196721,
            "TruthfulQA - EM (Fairness)": 0.4426229508196721,
            "TruthfulQA Mean Win Rate": 0.2013888888888889,
            "BIG-bench - EM": 0.005,
            "BIG-bench Mean Win Rate": 0.375,
            "GSM8K - EM": 0.0,
            "GSM8K Mean Win Rate": 0.03125,
            "BBQ - EM": 0.8524590163934426,
            "BBQ Mean Win Rate": 0.5625,
            "sam_sum - ROUGE-2": 0.0800283297278051,
            "sam_sum - Stereotypes (race)": 0.6666666666666667,
            "sam_sum - Stereotypes (gender)": 0.31844391882106576,
            "sam_sum - Representation (race)": 0.3333333333333333,
            "sam_sum - Representation (gender)": 0.026513569937369502,
            "sam_sum Mean Win Rate": 0.5083333333333333,
            "corr2cause - EM": 0.48,
            "corr2cause Mean Win Rate": 0.5,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.03182777501717458,
            "MATH Mean Win Rate": 0.125,
            "ethics_justice - EM": 0.72,
            "ethics_justice - EM (Robustness)": 0.685,
            "ethics_justice - EM (Fairness)": 0.635,
            "ethics_commonsense - EM": 0.45,
            "ethics_commonsense - EM (Robustness)": 0.33,
            "ethics_commonsense - EM (Fairness)": 0.39,
            "ethics_virtue - EM": 0.705,
            "ethics_virtue - EM (Robustness)": 0.615,
            "ethics_virtue - EM (Fairness)": 0.63,
            "ethics_deontology - EM": 0.635,
            "ethics_deontology - EM (Robustness)": 0.555,
            "ethics_deontology - EM (Fairness)": 0.565,
            "ethics_utilitarianism - EM": 0.65,
            "ethics_utilitarianism - EM (Robustness)": 0.43,
            "ethics_utilitarianism - EM (Fairness)": 0.555,
            "ethics Mean Win Rate": 0.5083333333333333,
            "Score_full": 0.31721378512250326,
            "Score_open": 0.2386663674939286,
            "Score_hidden": 0.35648749393679063
        }
    ],
    [
        "matthewdouglas_neurips_llm_challenge_2023_inference3",
        {
            "MMLU - EM": 0.6341307223751637,
            "MMLU - EM (Robustness)": 0.5846034593670397,
            "MMLU - EM (Fairness)": 0.592541572556349,
            "MMLU Mean Win Rate": 0.25,
            "TruthfulQA - EM": 0.39344262295081966,
            "TruthfulQA - EM (Robustness)": 0.29508196721311475,
            "TruthfulQA - EM (Fairness)": 0.3114754098360656,
            "TruthfulQA Mean Win Rate": 0.0,
            "BIG-bench - EM": 0.17295231694828472,
            "BIG-bench Mean Win Rate": 0.5,
            "GSM8K - EM": 0.5737704918032787,
            "GSM8K Mean Win Rate": 0.8125,
            "BBQ - EM": 0.7049180327868853,
            "BBQ Mean Win Rate": 0.0,
            "sam_sum - ROUGE-2": 0.18363352067827143,
            "sam_sum - Stereotypes (race)": null,
            "sam_sum - Stereotypes (gender)": 0.40108543417366943,
            "sam_sum - Representation (race)": 0.38666666666666666,
            "sam_sum - Representation (gender)": 0.04642857142857146,
            "sam_sum Mean Win Rate": 0.35833333333333334,
            "corr2cause - EM": 0.4625,
            "corr2cause Mean Win Rate": 0.125,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.17510174633043424,
            "MATH Mean Win Rate": 0.875,
            "ethics_justice - EM": 0.715,
            "ethics_justice - EM (Robustness)": 0.655,
            "ethics_justice - EM (Fairness)": 0.62,
            "ethics_commonsense - EM": 0.47,
            "ethics_commonsense - EM (Robustness)": 0.35,
            "ethics_commonsense - EM (Fairness)": 0.385,
            "ethics_virtue - EM": 0.715,
            "ethics_virtue - EM (Robustness)": 0.56,
            "ethics_virtue - EM (Fairness)": 0.625,
            "ethics_deontology - EM": 0.615,
            "ethics_deontology - EM (Robustness)": 0.48,
            "ethics_deontology - EM (Fairness)": 0.49,
            "ethics_utilitarianism - EM": 0.595,
            "ethics_utilitarianism - EM (Robustness)": 0.51,
            "ethics_utilitarianism - EM (Fairness)": 0.545,
            "ethics Mean Win Rate": 0.375,
            "Score_full": 0.23212284069043426,
            "Score_open": 3.0120386425337466e-130,
            "Score_hidden": 0.3481842610356514
        }
    ],
    [
        "teja1729_llm_challenge_4090_track_submission_1_evaluation",
        {
            "MMLU - EM": 0.6495287156474886,
            "MMLU - EM (Robustness)": 0.6049907629037943,
            "MMLU - EM (Fairness)": 0.6015372645305098,
            "MMLU Mean Win Rate": 0.75,
            "TruthfulQA - EM": 0.5409836065573771,
            "TruthfulQA - EM (Robustness)": 0.47540983606557374,
            "TruthfulQA - EM (Fairness)": 0.4426229508196721,
            "TruthfulQA Mean Win Rate": 0.24305555555555555,
            "BIG-bench - EM": 0.0011451612903225807,
            "BIG-bench Mean Win Rate": 0.25,
            "GSM8K - EM": 0.0,
            "GSM8K Mean Win Rate": 0.03125,
            "BBQ - EM": 0.8360655737704918,
            "BBQ Mean Win Rate": 0.375,
            "sam_sum - ROUGE-2": 0.05437254142950034,
            "sam_sum - Stereotypes (race)": 0.6666666666666667,
            "sam_sum - Stereotypes (gender)": 0.36795866738504185,
            "sam_sum - Representation (race)": 0.33333333333333337,
            "sam_sum - Representation (gender)": 0.024090462143559477,
            "sam_sum Mean Win Rate": 0.43333333333333335,
            "corr2cause - EM": 0.46,
            "corr2cause Mean Win Rate": 0.0,
            "MATH (chain-of-thoughts) - Equivalent (chain of thought)": 0.03041973161506149,
            "MATH Mean Win Rate": 0.0,
            "ethics_justice - EM": 0.68,
            "ethics_justice - EM (Robustness)": 0.64,
            "ethics_justice - EM (Fairness)": 0.625,
            "ethics_commonsense - EM": 0.505,
            "ethics_commonsense - EM (Robustness)": 0.345,
            "ethics_commonsense - EM (Fairness)": 0.425,
            "ethics_virtue - EM": 0.615,
            "ethics_virtue - EM (Robustness)": 0.495,
            "ethics_virtue - EM (Fairness)": 0.485,
            "ethics_deontology - EM": 0.645,
            "ethics_deontology - EM (Robustness)": 0.49,
            "ethics_deontology - EM (Fairness)": 0.565,
            "ethics_utilitarianism - EM": 0.595,
            "ethics_utilitarianism - EM (Robustness)": 0.425,
            "ethics_utilitarianism - EM (Fairness)": 0.455,
            "ethics Mean Win Rate": 0.3416666666666667,
            "Score_full": 0.07385780014188514,
            "Score_open": 0.22157340042565546,
            "Score_hidden": 1.3787912082678634e-162
        }
    ]
]